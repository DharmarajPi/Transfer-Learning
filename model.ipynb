{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "# loading the directories \n",
    "# importing the libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.applications import VGG16\n",
    "#from keras.preprocessing import image\n",
    "num_classes=3\n",
    "IMAGE_SHAPE = [224, 224]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
    "batch_size=32\n",
    "# loading the weights of VGG16 without the top layer. These weights are trained on Imagenet dataset.\n",
    "vgg = VGG16(input_shape = (224,224,3), weights = 'imagenet', include_top = False)  # input_shape = (64,64,3) as required by VGG\n",
    "\n",
    "# this will exclude the initial layers from training phase as there are already been trained.\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(vgg.output)\n",
    "x = Dense(128, activation = 'relu')(x)   # we can add a new fully connected layer but it will increase the execution time.\n",
    "x = Dense(64, activation = 'relu')(x) \n",
    "x = Dense(num_classes, activation = 'softmax')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 385 images belonging to 3 classes.\n",
      "Found 138 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "trdata = ImageDataGenerator()\n",
    "train_data_gen = trdata.flow_from_directory(directory=\"Train\",target_size=(224,224),shuffle=False, class_mode='categorical')\n",
    "tsdata = ImageDataGenerator()\n",
    "test_data_gen = tsdata.flow_from_directory(directory=\"Test\", target_size=(224,224),shuffle=False, class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-e042b1ca6718>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E642913DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E642913DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13/13 [==============================] - ETA: 0s - loss: 62.0823 - accuracy: 0.4364WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001E6442E2558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001E6442E2558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13/13 [==============================] - 98s 8s/step - loss: 62.0823 - accuracy: 0.4364 - val_loss: 33.8267 - val_accuracy: 0.3406\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 98s 8s/step - loss: 14.0897 - accuracy: 0.6805 - val_loss: 6.7669 - val_accuracy: 0.7319\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 99s 8s/step - loss: 0.9217 - accuracy: 0.9299 - val_loss: 4.7415 - val_accuracy: 0.7899\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 101s 8s/step - loss: 2.1274 - accuracy: 0.8987 - val_loss: 2.7657 - val_accuracy: 0.8768\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 102s 8s/step - loss: 3.3716 - accuracy: 0.8805 - val_loss: 2.6674 - val_accuracy: 0.8841\n",
      "Training Completed!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "epochs = 5\n",
    "#checkpoint = ModelCheckpoint(filepath='finalvgg16model.h5', verbose=1, save_best_only=True)\n",
    "training_steps_per_epoch = np.ceil(train_data_gen.samples / batch_size)\n",
    "validation_steps_per_epoch = np.ceil(test_data_gen.samples / batch_size)\n",
    "    \n",
    "model.fit_generator(train_data_gen, steps_per_epoch=training_steps_per_epoch, validation_data=test_data_gen, validation_steps=validation_steps_per_epoch,\n",
    "                        epochs=epochs, verbose=1)\n",
    "print('Training Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001E6443AB288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001E6443AB288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        59\n",
      "           1       0.91      0.96      0.94        53\n",
      "           2       0.78      0.69      0.73        26\n",
      "\n",
      "    accuracy                           0.88       138\n",
      "   macro avg       0.86      0.85      0.86       138\n",
      "weighted avg       0.88      0.88      0.88       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(test_data_gen, test_data_gen.samples / batch_size)\n",
    "val_preds = np.argmax(Y_pred, axis=1)\n",
    "import sklearn.metrics as metrics\n",
    "val_trues =test_data_gen.classes\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(val_trues, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53,  3,  3],\n",
       "       [ 0, 51,  2],\n",
       "       [ 6,  2, 18]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict(test_data_gen, test_data_gen.samples / batch_size)\n",
    "val_preds = np.argmax(Y_pred, axis=1)\n",
    "import sklearn.metrics as metrics\n",
    "val_trues =test_data_gen.classes\n",
    "cm = metrics.confusion_matrix(val_trues, val_preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_file=\"Model.h5\"\n",
    "tf.keras.models.save_model(model,keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orange\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "img_path = 'fresh.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds=model.predict(x)\n",
    "# create a list containing the class labels\n",
    "class_labels = ['Apple','Banana','Orange']\n",
    "\n",
    "# find the index of the class with maximum score\n",
    "pred = np.argmax(preds, axis=-1)\n",
    "\n",
    "# print the label of the class with maximum score\n",
    "print(class_labels[pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
